file,method_name,new_method_name,start_line,end_line,original_code,code,var
./sklearn/preprocessing/_discretization.py,fit,fit_discretizer,116,189,"def fit(self, X, y=None):
    """"""Fits the estimator.

        Parameters
        ----------
        X : numeric array-like, shape (n_samples, n_features)
            Data to be discretized.

        y : ignored

        Returns
        -------
        self
        """"""
    X = check_array(X, dtype='numeric')
    valid_encode = ('onehot', 'onehot-dense', 'ordinal')
    if self.encode not in valid_encode:
        raise ValueError(""Valid options for 'encode' are {}. Got encode={!r} instead."".format(valid_encode, self.encode))
    valid_strategy = ('uniform', 'quantile', 'kmeans')
    if self.strategy not in valid_strategy:
        raise ValueError(""Valid options for 'strategy' are {}. Got strategy={!r} instead."".format(valid_strategy, self.strategy))
    n_features = X.shape[1]
    n_bins = self._validate_n_bins(n_features)
    bin_edges = np.zeros(n_features, dtype=object)
    for jj in range(n_features):
        column = X[:, jj]
        col_min, col_max = (column.min(), column.max())
        if col_min == col_max:
            warnings.warn('Feature %d is constant and will be replaced with 0.' % jj)
            n_bins[jj] = 1
            bin_edges[jj] = np.array([-np.inf, np.inf])
            continue
        if self.strategy == 'uniform':
            bin_edges[jj] = np.linspace(col_min, col_max, n_bins[jj] + 1)
        elif self.strategy == 'quantile':
            quantiles = np.linspace(0, 100, n_bins[jj] + 1)
            bin_edges[jj] = np.asarray(np.percentile(column, quantiles))
        elif self.strategy == 'kmeans':
            from ..cluster import KMeans
            uniform_edges = np.linspace(col_min, col_max, n_bins[jj] + 1)
            init = (uniform_edges[1:] + uniform_edges[:-1])[:, None] * 0.5
            km = KMeans(n_clusters=n_bins[jj], init=init, n_init=1)
            centers = km.fit(column[:, None]).cluster_centers_[:, 0]
            bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5
            bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]
    self.bin_edges_ = bin_edges
    self.n_bins_ = n_bins
    if 'onehot' in self.encode:
        self._encoder = OneHotEncoder(categories=[np.arange(i) for i in self.n_bins_], sparse=self.encode == 'onehot')
        self._encoder.fit(np.zeros((1, len(self.n_bins_)), dtype=int))
    return self","def fit_discretizer(self, X, y=None):
    """"""Fits the estimator.

        Parameters
        ----------
        X : numeric array-like, shape (n_samples, n_features)
            Data to be discretized.

        y : ignored

        Returns
        -------
        self
        """"""
    X = check_array(X, dtype='numeric')
    valid_encode = ('onehot', 'onehot-dense', 'ordinal')
    if self.encode not in valid_encode:
        raise ValueError(""Valid options for 'encode' are {}. Got encode={!r} instead."".format(valid_encode, self.encode))
    valid_strategy = ('uniform', 'quantile', 'kmeans')
    if self.strategy not in valid_strategy:
        raise ValueError(""Valid options for 'strategy' are {}. Got strategy={!r} instead."".format(valid_strategy, self.strategy))
    n_features = X.shape[1]
    n_bins = self._validate_n_bins(n_features)
    bin_edges = np.zeros(n_features, dtype=object)
    for jj in range(n_features):
        column = X[:, jj]
        col_min, col_max = (column.min(), column.max())
        if col_min == col_max:
            warnings.warn('Feature %d is constant and will be replaced with 0.' % jj)
            n_bins[jj] = 1
            bin_edges[jj] = np.array([-np.inf, np.inf])
            continue
        if self.strategy == 'uniform':
            bin_edges[jj] = np.linspace(col_min, col_max, n_bins[jj] + 1)
        elif self.strategy == 'quantile':
            quantiles = np.linspace(0, 100, n_bins[jj] + 1)
            bin_edges[jj] = np.asarray(np.percentile(column, quantiles))
        elif self.strategy == 'kmeans':
            from ..cluster import KMeans
            uniform_edges = np.linspace(col_min, col_max, n_bins[jj] + 1)
            init = (uniform_edges[1:] + uniform_edges[:-1])[:, None] * 0.5
            km = KMeans(n_clusters=n_bins[jj], init=init, n_init=1)
            centers = km.fit(column[:, None]).cluster_centers_[:, 0]
            bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5
            bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]
    self.bin_edges_ = bin_edges
    self.n_bins_ = n_bins
    if 'onehot' in self.encode:
        self._encoder = OneHotEncoder(categories=[np.arange(i) for i in self.n_bins_], sparse=self.encode == 'onehot')
        self._encoder.fit(np.zeros((1, len(self.n_bins_)), dtype=int))
    return self","[{""var"": ""valid_strategy"", ""rename"": ""permitted_strategy_options""}, {""var"": ""column"", ""rename"": ""feature_column_data""}, {""var"": ""quantiles"", ""rename"": ""percentile_thresholds""}, {""var"": ""init"", ""rename"": ""initial_bin_centers""}, {""var"": ""i"", ""rename"": ""bin_count""}, {""var"": ""bin_edges"", ""rename"": ""feature_bin_boundaries""}, {""var"": ""col_min"", ""rename"": ""column_minimum""}, {""var"": ""n_features"", ""rename"": ""num_features""}, {""var"": ""centers"", ""rename"": ""cluster_centers_kmeans""}, {""var"": ""jj"", ""rename"": ""feature_index""}, {""var"": ""km"", ""rename"": ""kmeans_model""}, {""var"": ""valid_encode"", ""rename"": ""valid_encoding_options""}, {""var"": ""n_bins"", ""rename"": ""num_bins_per_feature""}, {""var"": ""col_max"", ""rename"": ""column_maximum_value""}, {""var"": ""uniform_edges"", ""rename"": ""initial_kmeans_edges""}]"
