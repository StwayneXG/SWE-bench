file,method_name,new_method_name,start_line,end_line,original_code,code,var
./sklearn/linear_model/logistic.py,fit,fit_with_cross_validation_and_regularization,1936,2212,"def fit(self, X, y, sample_weight=None):
    """"""Fit the model according to the given training data.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape (n_samples, n_features)
            Training vector, where n_samples is the number of samples and
            n_features is the number of features.

        y : array-like, shape (n_samples,)
            Target vector relative to X.

        sample_weight : array-like, shape (n_samples,) optional
            Array of weights that are assigned to individual samples.
            If not provided, then each sample is given unit weight.

        Returns
        -------
        self : object
        """"""
    solver = _check_solver(self.solver, self.penalty, self.dual)
    if not isinstance(self.max_iter, numbers.Number) or self.max_iter < 0:
        raise ValueError('Maximum number of iteration must be positive; got (max_iter=%r)' % self.max_iter)
    if not isinstance(self.tol, numbers.Number) or self.tol < 0:
        raise ValueError('Tolerance for stopping criteria must be positive; got (tol=%r)' % self.tol)
    if self.penalty == 'elasticnet':
        if self.l1_ratios is None or len(self.l1_ratios) == 0 or any((not isinstance(l1_ratio, numbers.Number) or l1_ratio < 0 or l1_ratio > 1 for l1_ratio in self.l1_ratios)):
            raise ValueError('l1_ratios must be a list of numbers between 0 and 1; got (l1_ratios=%r)' % self.l1_ratios)
        l1_ratios_ = self.l1_ratios
    else:
        if self.l1_ratios is not None:
            warnings.warn(""l1_ratios parameter is only used when penalty is 'elasticnet'. Got (penalty={})"".format(self.penalty))
        l1_ratios_ = [None]
    if self.penalty == 'none':
        raise ValueError(""penalty='none' is not useful and not supported by LogisticRegressionCV."")
    X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64, order='C', accept_large_sparse=solver != 'liblinear')
    check_classification_targets(y)
    class_weight = self.class_weight
    label_encoder = LabelEncoder().fit(y)
    y = label_encoder.transform(y)
    if isinstance(class_weight, dict):
        class_weight = {label_encoder.transform([cls])[0]: v for cls, v in class_weight.items()}
    classes = self.classes_ = label_encoder.classes_
    encoded_labels = label_encoder.transform(label_encoder.classes_)
    multi_class = _check_multi_class(self.multi_class, solver, len(classes))
    if solver in ['sag', 'saga']:
        max_squared_sum = row_norms(X, squared=True).max()
    else:
        max_squared_sum = None
    cv = check_cv(self.cv, y, classifier=True)
    folds = list(cv.split(X, y))
    n_classes = len(encoded_labels)
    if n_classes < 2:
        raise ValueError('This solver needs samples of at least 2 classes in the data, but the data contains only one class: %r' % classes[0])
    if n_classes == 2:
        n_classes = 1
        encoded_labels = encoded_labels[1:]
        classes = classes[1:]
    if multi_class == 'multinomial':
        iter_encoded_labels = iter_classes = [None]
    else:
        iter_encoded_labels = encoded_labels
        iter_classes = classes
    if class_weight == 'balanced':
        class_weight = compute_class_weight(class_weight, np.arange(len(self.classes_)), y)
        class_weight = dict(enumerate(class_weight))
    path_func = delayed(_log_reg_scoring_path)
    if self.solver in ['sag', 'saga']:
        prefer = 'threads'
    else:
        prefer = 'processes'
    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, **_joblib_parallel_args(prefer=prefer))((path_func(X, y, train, test, pos_class=label, Cs=self.Cs, fit_intercept=self.fit_intercept, penalty=self.penalty, dual=self.dual, solver=solver, tol=self.tol, max_iter=self.max_iter, verbose=self.verbose, class_weight=class_weight, scoring=self.scoring, multi_class=multi_class, intercept_scaling=self.intercept_scaling, random_state=self.random_state, max_squared_sum=max_squared_sum, sample_weight=sample_weight, l1_ratio=l1_ratio) for label in iter_encoded_labels for train, test in folds for l1_ratio in l1_ratios_))
    coefs_paths, Cs, scores, n_iter_ = zip(*fold_coefs_)
    self.Cs_ = Cs[0]
    if multi_class == 'multinomial':
        coefs_paths = np.reshape(coefs_paths, (len(folds), len(l1_ratios_) * len(self.Cs_), n_classes, -1))
        coefs_paths = np.swapaxes(coefs_paths, 0, 1)
        coefs_paths = np.swapaxes(coefs_paths, 0, 2)
        self.n_iter_ = np.reshape(n_iter_, (1, len(folds), len(self.Cs_) * len(l1_ratios_)))
        scores = np.tile(scores, (n_classes, 1, 1))
    else:
        coefs_paths = np.reshape(coefs_paths, (n_classes, len(folds), len(self.Cs_) * len(l1_ratios_), -1))
        self.n_iter_ = np.reshape(n_iter_, (n_classes, len(folds), len(self.Cs_) * len(l1_ratios_)))
    scores = np.reshape(scores, (n_classes, len(folds), -1))
    self.scores_ = dict(zip(classes, scores))
    self.coefs_paths_ = dict(zip(classes, coefs_paths))
    self.C_ = list()
    self.l1_ratio_ = list()
    self.coef_ = np.empty((n_classes, X.shape[1]))
    self.intercept_ = np.zeros(n_classes)
    for index, (cls, encoded_label) in enumerate(zip(iter_classes, iter_encoded_labels)):
        if multi_class == 'ovr':
            scores = self.scores_[cls]
            coefs_paths = self.coefs_paths_[cls]
        else:
            scores = scores[0]
        if self.refit:
            best_index = scores.sum(axis=0).argmax()
            best_index_C = best_index % len(self.Cs_)
            C_ = self.Cs_[best_index_C]
            self.C_.append(C_)
            best_index_l1 = best_index // len(self.Cs_)
            l1_ratio_ = l1_ratios_[best_index_l1]
            self.l1_ratio_.append(l1_ratio_)
            if multi_class == 'multinomial':
                coef_init = np.mean(coefs_paths[:, :, best_index, :], axis=1)
            else:
                coef_init = np.mean(coefs_paths[:, best_index, :], axis=0)
            w, _, _ = _logistic_regression_path(X, y, pos_class=encoded_label, Cs=[C_], solver=solver, fit_intercept=self.fit_intercept, coef=coef_init, max_iter=self.max_iter, tol=self.tol, penalty=self.penalty, class_weight=class_weight, multi_class=multi_class, verbose=max(0, self.verbose - 1), random_state=self.random_state, check_input=False, max_squared_sum=max_squared_sum, sample_weight=sample_weight, l1_ratio=l1_ratio_)
            w = w[0]
        else:
            best_indices = np.argmax(scores, axis=1)
            if self.multi_class == 'ovr':
                w = np.mean([coefs_paths[i, best_indices[i], :] for i in range(len(folds))], axis=0)
            else:
                w = np.mean([coefs_paths[:, i, best_indices[i], :] for i in range(len(folds))], axis=0)
            best_indices_C = best_indices % len(self.Cs_)
            self.C_.append(np.mean(self.Cs_[best_indices_C]))
            best_indices_l1 = best_indices // len(self.Cs_)
            self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))
        if multi_class == 'multinomial':
            self.C_ = np.tile(self.C_, n_classes)
            self.l1_ratio_ = np.tile(self.l1_ratio_, n_classes)
            self.coef_ = w[:, :X.shape[1]]
            if self.fit_intercept:
                self.intercept_ = w[:, -1]
        else:
            self.coef_[index] = w[:X.shape[1]]
            if self.fit_intercept:
                self.intercept_[index] = w[-1]
    self.C_ = np.asarray(self.C_)
    self.l1_ratio_ = np.asarray(self.l1_ratio_)
    self.l1_ratios_ = np.asarray(l1_ratios_)
    if self.l1_ratios is not None:
        for cls, coefs_path in self.coefs_paths_.items():
            self.coefs_paths_[cls] = coefs_path.reshape((len(folds), self.Cs_.size, self.l1_ratios_.size, -1))
        for cls, score in self.scores_.items():
            self.scores_[cls] = score.reshape((len(folds), self.Cs_.size, self.l1_ratios_.size))
        self.n_iter_ = self.n_iter_.reshape((-1, len(folds), self.Cs_.size, self.l1_ratios_.size))
    return self","def fit_with_cross_validation_and_regularization(self, X, y, sample_weight=None):
    """"""Fit the model according to the given training data.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape (n_samples, n_features)
            Training vector, where n_samples is the number of samples and
            n_features is the number of features.

        y : array-like, shape (n_samples,)
            Target vector relative to X.

        sample_weight : array-like, shape (n_samples,) optional
            Array of weights that are assigned to individual samples.
            If not provided, then each sample is given unit weight.

        Returns
        -------
        self : object
        """"""
    solver = _check_solver(self.solver, self.penalty, self.dual)
    if not isinstance(self.max_iter, numbers.Number) or self.max_iter < 0:
        raise ValueError('Maximum number of iteration must be positive; got (max_iter=%r)' % self.max_iter)
    if not isinstance(self.tol, numbers.Number) or self.tol < 0:
        raise ValueError('Tolerance for stopping criteria must be positive; got (tol=%r)' % self.tol)
    if self.penalty == 'elasticnet':
        if self.l1_ratios is None or len(self.l1_ratios) == 0 or any((not isinstance(l1_ratio, numbers.Number) or l1_ratio < 0 or l1_ratio > 1 for l1_ratio in self.l1_ratios)):
            raise ValueError('l1_ratios must be a list of numbers between 0 and 1; got (l1_ratios=%r)' % self.l1_ratios)
        l1_ratios_ = self.l1_ratios
    else:
        if self.l1_ratios is not None:
            warnings.warn(""l1_ratios parameter is only used when penalty is 'elasticnet'. Got (penalty={})"".format(self.penalty))
        l1_ratios_ = [None]
    if self.penalty == 'none':
        raise ValueError(""penalty='none' is not useful and not supported by LogisticRegressionCV."")
    X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64, order='C', accept_large_sparse=solver != 'liblinear')
    check_classification_targets(y)
    class_weight = self.class_weight
    label_encoder = LabelEncoder().fit(y)
    y = label_encoder.transform(y)
    if isinstance(class_weight, dict):
        class_weight = {label_encoder.transform([cls])[0]: v for cls, v in class_weight.items()}
    classes = self.classes_ = label_encoder.classes_
    encoded_labels = label_encoder.transform(label_encoder.classes_)
    multi_class = _check_multi_class(self.multi_class, solver, len(classes))
    if solver in ['sag', 'saga']:
        max_squared_sum = row_norms(X, squared=True).max()
    else:
        max_squared_sum = None
    cv = check_cv(self.cv, y, classifier=True)
    folds = list(cv.split(X, y))
    n_classes = len(encoded_labels)
    if n_classes < 2:
        raise ValueError('This solver needs samples of at least 2 classes in the data, but the data contains only one class: %r' % classes[0])
    if n_classes == 2:
        n_classes = 1
        encoded_labels = encoded_labels[1:]
        classes = classes[1:]
    if multi_class == 'multinomial':
        iter_encoded_labels = iter_classes = [None]
    else:
        iter_encoded_labels = encoded_labels
        iter_classes = classes
    if class_weight == 'balanced':
        class_weight = compute_class_weight(class_weight, np.arange(len(self.classes_)), y)
        class_weight = dict(enumerate(class_weight))
    path_func = delayed(_log_reg_scoring_path)
    if self.solver in ['sag', 'saga']:
        prefer = 'threads'
    else:
        prefer = 'processes'
    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, **_joblib_parallel_args(prefer=prefer))((path_func(X, y, train, test, pos_class=label, Cs=self.Cs, fit_intercept=self.fit_intercept, penalty=self.penalty, dual=self.dual, solver=solver, tol=self.tol, max_iter=self.max_iter, verbose=self.verbose, class_weight=class_weight, scoring=self.scoring, multi_class=multi_class, intercept_scaling=self.intercept_scaling, random_state=self.random_state, max_squared_sum=max_squared_sum, sample_weight=sample_weight, l1_ratio=l1_ratio) for label in iter_encoded_labels for train, test in folds for l1_ratio in l1_ratios_))
    coefs_paths, Cs, scores, n_iter_ = zip(*fold_coefs_)
    self.Cs_ = Cs[0]
    if multi_class == 'multinomial':
        coefs_paths = np.reshape(coefs_paths, (len(folds), len(l1_ratios_) * len(self.Cs_), n_classes, -1))
        coefs_paths = np.swapaxes(coefs_paths, 0, 1)
        coefs_paths = np.swapaxes(coefs_paths, 0, 2)
        self.n_iter_ = np.reshape(n_iter_, (1, len(folds), len(self.Cs_) * len(l1_ratios_)))
        scores = np.tile(scores, (n_classes, 1, 1))
    else:
        coefs_paths = np.reshape(coefs_paths, (n_classes, len(folds), len(self.Cs_) * len(l1_ratios_), -1))
        self.n_iter_ = np.reshape(n_iter_, (n_classes, len(folds), len(self.Cs_) * len(l1_ratios_)))
    scores = np.reshape(scores, (n_classes, len(folds), -1))
    self.scores_ = dict(zip(classes, scores))
    self.coefs_paths_ = dict(zip(classes, coefs_paths))
    self.C_ = list()
    self.l1_ratio_ = list()
    self.coef_ = np.empty((n_classes, X.shape[1]))
    self.intercept_ = np.zeros(n_classes)
    for index, (cls, encoded_label) in enumerate(zip(iter_classes, iter_encoded_labels)):
        if multi_class == 'ovr':
            scores = self.scores_[cls]
            coefs_paths = self.coefs_paths_[cls]
        else:
            scores = scores[0]
        if self.refit:
            best_index = scores.sum(axis=0).argmax()
            best_index_C = best_index % len(self.Cs_)
            C_ = self.Cs_[best_index_C]
            self.C_.append(C_)
            best_index_l1 = best_index // len(self.Cs_)
            l1_ratio_ = l1_ratios_[best_index_l1]
            self.l1_ratio_.append(l1_ratio_)
            if multi_class == 'multinomial':
                coef_init = np.mean(coefs_paths[:, :, best_index, :], axis=1)
            else:
                coef_init = np.mean(coefs_paths[:, best_index, :], axis=0)
            w, _, _ = _logistic_regression_path(X, y, pos_class=encoded_label, Cs=[C_], solver=solver, fit_intercept=self.fit_intercept, coef=coef_init, max_iter=self.max_iter, tol=self.tol, penalty=self.penalty, class_weight=class_weight, multi_class=multi_class, verbose=max(0, self.verbose - 1), random_state=self.random_state, check_input=False, max_squared_sum=max_squared_sum, sample_weight=sample_weight, l1_ratio=l1_ratio_)
            w = w[0]
        else:
            best_indices = np.argmax(scores, axis=1)
            if self.multi_class == 'ovr':
                w = np.mean([coefs_paths[i, best_indices[i], :] for i in range(len(folds))], axis=0)
            else:
                w = np.mean([coefs_paths[:, i, best_indices[i], :] for i in range(len(folds))], axis=0)
            best_indices_C = best_indices % len(self.Cs_)
            self.C_.append(np.mean(self.Cs_[best_indices_C]))
            best_indices_l1 = best_indices // len(self.Cs_)
            self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))
        if multi_class == 'multinomial':
            self.C_ = np.tile(self.C_, n_classes)
            self.l1_ratio_ = np.tile(self.l1_ratio_, n_classes)
            self.coef_ = w[:, :X.shape[1]]
            if self.fit_intercept:
                self.intercept_ = w[:, -1]
        else:
            self.coef_[index] = w[:X.shape[1]]
            if self.fit_intercept:
                self.intercept_[index] = w[-1]
    self.C_ = np.asarray(self.C_)
    self.l1_ratio_ = np.asarray(self.l1_ratio_)
    self.l1_ratios_ = np.asarray(l1_ratios_)
    if self.l1_ratios is not None:
        for cls, coefs_path in self.coefs_paths_.items():
            self.coefs_paths_[cls] = coefs_path.reshape((len(folds), self.Cs_.size, self.l1_ratios_.size, -1))
        for cls, score in self.scores_.items():
            self.scores_[cls] = score.reshape((len(folds), self.Cs_.size, self.l1_ratios_.size))
        self.n_iter_ = self.n_iter_.reshape((-1, len(folds), self.Cs_.size, self.l1_ratios_.size))
    return self","[{""var"": ""best_indices_l1"", ""rename"": ""optimal_l1_ratio_indices""}, {""var"": ""l1_ratio_"", ""rename"": ""elasticnet_penalty_weights""}, {""var"": ""i"", ""rename"": ""fold_index""}, {""var"": ""n_iter_"", ""rename"": ""cross_validation_iterations""}, {""var"": ""encoded_label"", ""rename"": ""transformed_classes""}, {""var"": ""best_indices"", ""rename"": ""optimal_score_indices""}, {""var"": ""solver"", ""rename"": ""optimization_method""}, {""var"": ""label"", ""rename"": ""original_class_labels""}, {""var"": ""coef_init"", ""rename"": ""average_initial_coefficients""}, {""var"": ""fold_coefs_"", ""rename"": ""cross_val_fold_results""}, {""var"": ""l1_ratios_"", ""rename"": ""elasticnet_l1_ratios""}, {""var"": ""coefs_path"", ""rename"": ""coefficients_training_path""}, {""var"": ""multi_class"", ""rename"": ""classification_scheme""}, {""var"": ""class_weight"", ""rename"": ""class_weight_strategy""}, {""var"": ""score"", ""rename"": ""model_fit_score""}, {""var"": ""best_indices_C"", ""rename"": ""optimal_C_indices""}, {""var"": ""train"", ""rename"": ""training_indices""}, {""var"": ""best_index"", ""rename"": ""optimal_hyperparam_index""}, {""var"": ""n_classes"", ""rename"": ""num_encoded_labels""}, {""var"": ""w"", ""rename"": ""model_coefficients""}, {""var"": ""best_index_C"", ""rename"": ""best_regularization_index""}, {""var"": ""l1_ratio"", ""rename"": ""elastic_net_l1_ratio""}, {""var"": ""classes"", ""rename"": ""target_classes""}, {""var"": ""prefer"", ""rename"": ""prefer_parallelization_mode""}, {""var"": ""v"", ""rename"": ""class_weight_transformed""}, {""var"": ""cv"", ""rename"": ""cross_validator""}, {""var"": ""path_func"", ""rename"": ""logistic_regression_scoring_path""}, {""var"": ""index"", ""rename"": ""sample_index""}, {""var"": ""folds"", ""rename"": ""cross_validation_splits""}, {""var"": ""max_squared_sum"", ""rename"": ""largest_row_norm_squared""}, {""var"": ""encoded_labels"", ""rename"": ""transformed_label_indices""}, {""var"": ""test"", ""rename"": ""fit_model_to_training_data""}, {""var"": ""iter_encoded_labels"", ""rename"": ""target_class_labels""}, {""var"": ""coefs_paths"", ""rename"": ""coefficient_evolution_paths""}, {""var"": ""Cs"", ""rename"": ""regularization_constants""}, {""var"": ""_"", ""rename"": ""initial_placeholder""}, {""var"": ""iter_classes"", ""rename"": ""class_iteration_labels""}, {""var"": ""scores"", ""rename"": ""model_evaluation_scores""}, {""var"": ""cls"", ""rename"": ""current_class_label""}, {""var"": ""best_index_l1"", ""rename"": ""best_l1_ratio_index""}, {""var"": ""C_"", ""rename"": ""optimal_regularization_strength""}, {""var"": ""label_encoder"", ""rename"": ""target_label_encoder""}]"
