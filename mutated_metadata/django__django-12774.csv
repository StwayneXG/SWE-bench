file,method_name,new_method_name,start_line,end_line,original_code,code,var
./django/db/models/query.py,in_bulk,map_ids_to_objects,685,711,"def in_bulk(self, id_list=None, *, field_name='pk'):
    """"""
        Return a dictionary mapping each of the given IDs to the object with
        that ID. If `id_list` isn't provided, evaluate the entire QuerySet.
        """"""
    assert not self.query.is_sliced, ""Cannot use 'limit' or 'offset' with in_bulk""
    if field_name != 'pk' and (not self.model._meta.get_field(field_name).unique):
        raise ValueError(""in_bulk()'s field_name must be a unique field but %r isn't."" % field_name)
    if id_list is not None:
        if not id_list:
            return {}
        filter_key = '{}__in'.format(field_name)
        batch_size = connections[self.db].features.max_query_params
        id_list = tuple(id_list)
        if batch_size and batch_size < len(id_list):
            qs = ()
            for offset in range(0, len(id_list), batch_size):
                batch = id_list[offset:offset + batch_size]
                qs += tuple(self.filter(**{filter_key: batch}).order_by())
        else:
            qs = self.filter(**{filter_key: id_list}).order_by()
    else:
        qs = self._chain()
    return {getattr(obj, field_name): obj for obj in qs}","def map_ids_to_objects(self, id_list=None, *, field_name='pk'):
    """"""
        Return a dictionary mapping each of the given IDs to the object with
        that ID. If `id_list` isn't provided, evaluate the entire QuerySet.
        """"""
    assert not self.query.is_sliced, ""Cannot use 'limit' or 'offset' with in_bulk""
    if field_name != 'pk' and (not self.model._meta.get_field(field_name).unique):
        raise ValueError(""in_bulk()'s field_name must be a unique field but %r isn't."" % field_name)
    if id_list is not None:
        if not id_list:
            return {}
        filter_key = '{}__in'.format(field_name)
        batch_size = connections[self.db].features.max_query_params
        id_list = tuple(id_list)
        if batch_size and batch_size < len(id_list):
            qs = ()
            for offset in range(0, len(id_list), batch_size):
                batch = id_list[offset:offset + batch_size]
                qs += tuple(self.filter(**{filter_key: batch}).order_by())
        else:
            qs = self.filter(**{filter_key: id_list}).order_by()
    else:
        qs = self._chain()
    return {getattr(obj, field_name): obj for obj in qs}","[{""var"": ""offset"", ""rename"": ""batch_start_index""}, {""var"": ""batch_size"", ""rename"": ""max_query_batch_size""}, {""var"": ""obj"", ""rename"": ""object_dict""}, {""var"": ""batch"", ""rename"": ""id_batch""}, {""var"": ""filter_key"", ""rename"": ""field_lookup_key""}, {""var"": ""qs"", ""rename"": ""queryset_result""}]"
