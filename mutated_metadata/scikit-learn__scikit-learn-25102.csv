file,method_name,new_method_name,start_line,end_line,original_code,code,var
./sklearn/base.py,_validate_data,validate_and_configure_input_data,495,602,"def _validate_data(self, X='no_validation', y='no_validation', reset=True, validate_separately=False, **check_params):
    """"""Validate input data and set or check the `n_features_in_` attribute.

        Parameters
        ----------
        X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features), default='no validation'
            The input samples.
            If `'no_validation'`, no validation is performed on `X`. This is
            useful for meta-estimator which can delegate input validation to
            their underlying estimator(s). In that case `y` must be passed and
            the only accepted `check_params` are `multi_output` and
            `y_numeric`.

        y : array-like of shape (n_samples,), default='no_validation'
            The targets.

            - If `None`, `check_array` is called on `X`. If the estimator's
              requires_y tag is True, then an error will be raised.
            - If `'no_validation'`, `check_array` is called on `X` and the
              estimator's requires_y tag is ignored. This is a default
              placeholder and is never meant to be explicitly set. In that case
              `X` must be passed.
            - Otherwise, only `y` with `_check_y` or both `X` and `y` are
              checked with either `check_array` or `check_X_y` depending on
              `validate_separately`.

        reset : bool, default=True
            Whether to reset the `n_features_in_` attribute.
            If False, the input will be checked for consistency with data
            provided when reset was last True.
            .. note::
               It is recommended to call reset=True in `fit` and in the first
               call to `partial_fit`. All other methods that validate `X`
               should set `reset=False`.

        validate_separately : False or tuple of dicts, default=False
            Only used if y is not None.
            If False, call validate_X_y(). Else, it must be a tuple of kwargs
            to be used for calling check_array() on X and y respectively.

            `estimator=self` is automatically added to these dicts to generate
            more informative error message in case of invalid input data.

        **check_params : kwargs
            Parameters passed to :func:`sklearn.utils.check_array` or
            :func:`sklearn.utils.check_X_y`. Ignored if validate_separately
            is not False.

            `estimator=self` is automatically added to these params to generate
            more informative error message in case of invalid input data.

        Returns
        -------
        out : {ndarray, sparse matrix} or tuple of these
            The validated input. A tuple is returned if both `X` and `y` are
            validated.
        """"""
    self._check_feature_names(X, reset=reset)
    if y is None and self._get_tags()['requires_y']:
        raise ValueError(f'This {self.__class__.__name__} estimator requires y to be passed, but the target y is None.')
    no_val_X = isinstance(X, str) and X == 'no_validation'
    no_val_y = y is None or (isinstance(y, str) and y == 'no_validation')
    default_check_params = {'estimator': self}
    check_params = {**default_check_params, **check_params}
    if no_val_X and no_val_y:
        raise ValueError('Validation should be done on X, y or both.')
    elif not no_val_X and no_val_y:
        X = check_array(X, input_name='X', **check_params)
        out = X
    elif no_val_X and (not no_val_y):
        y = _check_y(y, **check_params)
        out = y
    else:
        if validate_separately:
            check_X_params, check_y_params = validate_separately
            if 'estimator' not in check_X_params:
                check_X_params = {**default_check_params, **check_X_params}
            X = check_array(X, input_name='X', **check_X_params)
            if 'estimator' not in check_y_params:
                check_y_params = {**default_check_params, **check_y_params}
            y = check_array(y, input_name='y', **check_y_params)
        else:
            X, y = check_X_y(X, y, **check_params)
        out = (X, y)
    if not no_val_X and check_params.get('ensure_2d', True):
        self._check_n_features(X, reset=reset)
    return out","def validate_and_configure_input_data(self, X='no_validation', y='no_validation', reset=True, validate_separately=False, **check_params):
    """"""Validate input data and set or check the `n_features_in_` attribute.

        Parameters
        ----------
        X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features), default='no validation'
            The input samples.
            If `'no_validation'`, no validation is performed on `X`. This is
            useful for meta-estimator which can delegate input validation to
            their underlying estimator(s). In that case `y` must be passed and
            the only accepted `check_params` are `multi_output` and
            `y_numeric`.

        y : array-like of shape (n_samples,), default='no_validation'
            The targets.

            - If `None`, `check_array` is called on `X`. If the estimator's
              requires_y tag is True, then an error will be raised.
            - If `'no_validation'`, `check_array` is called on `X` and the
              estimator's requires_y tag is ignored. This is a default
              placeholder and is never meant to be explicitly set. In that case
              `X` must be passed.
            - Otherwise, only `y` with `_check_y` or both `X` and `y` are
              checked with either `check_array` or `check_X_y` depending on
              `validate_separately`.

        reset : bool, default=True
            Whether to reset the `n_features_in_` attribute.
            If False, the input will be checked for consistency with data
            provided when reset was last True.
            .. note::
               It is recommended to call reset=True in `fit` and in the first
               call to `partial_fit`. All other methods that validate `X`
               should set `reset=False`.

        validate_separately : False or tuple of dicts, default=False
            Only used if y is not None.
            If False, call validate_X_y(). Else, it must be a tuple of kwargs
            to be used for calling check_array() on X and y respectively.

            `estimator=self` is automatically added to these dicts to generate
            more informative error message in case of invalid input data.

        **check_params : kwargs
            Parameters passed to :func:`sklearn.utils.check_array` or
            :func:`sklearn.utils.check_X_y`. Ignored if validate_separately
            is not False.

            `estimator=self` is automatically added to these params to generate
            more informative error message in case of invalid input data.

        Returns
        -------
        out : {ndarray, sparse matrix} or tuple of these
            The validated input. A tuple is returned if both `X` and `y` are
            validated.
        """"""
    self._check_feature_names(X, reset=reset)
    if y is None and self._get_tags()['requires_y']:
        raise ValueError(f'This {self.__class__.__name__} estimator requires y to be passed, but the target y is None.')
    no_val_X = isinstance(X, str) and X == 'no_validation'
    no_val_y = y is None or (isinstance(y, str) and y == 'no_validation')
    default_check_params = {'estimator': self}
    check_params = {**default_check_params, **check_params}
    if no_val_X and no_val_y:
        raise ValueError('Validation should be done on X, y or both.')
    elif not no_val_X and no_val_y:
        X = check_array(X, input_name='X', **check_params)
        out = X
    elif no_val_X and (not no_val_y):
        y = _check_y(y, **check_params)
        out = y
    else:
        if validate_separately:
            check_X_params, check_y_params = validate_separately
            if 'estimator' not in check_X_params:
                check_X_params = {**default_check_params, **check_X_params}
            X = check_array(X, input_name='X', **check_X_params)
            if 'estimator' not in check_y_params:
                check_y_params = {**default_check_params, **check_y_params}
            y = check_array(y, input_name='y', **check_y_params)
        else:
            X, y = check_X_y(X, y, **check_params)
        out = (X, y)
    if not no_val_X and check_params.get('ensure_2d', True):
        self._check_n_features(X, reset=reset)
    return out","[{""var"": ""out"", ""rename"": ""validated_data""}, {""var"": ""default_check_params"", ""rename"": ""initial_validation_params""}, {""var"": ""no_val_y"", ""rename"": ""requires_y_validation""}, {""var"": ""no_val_X"", ""rename"": ""skip_validation_X""}, {""var"": ""check_y_params"", ""rename"": ""validation_params_for_y""}, {""var"": ""check_X_params"", ""rename"": ""X_validation_parameters""}]"
./sklearn/feature_selection/_base.py,transform,reduce_to_selected_features,68,90,"def transform(self, X):
    """"""Reduce X to the selected features.

        Parameters
        ----------
        X : array of shape [n_samples, n_features]
            The input samples.

        Returns
        -------
        X_r : array of shape [n_samples, n_selected_features]
            The input samples with only the selected features.
        """"""
    X = self._validate_data(X, dtype=None, accept_sparse='csr', force_all_finite=not _safe_tags(self, key='allow_nan'), reset=False)
    return self._transform(X)","def reduce_to_selected_features(self, X):
    """"""Reduce X to the selected features.

        Parameters
        ----------
        X : array of shape [n_samples, n_features]
            The input samples.

        Returns
        -------
        X_r : array of shape [n_samples, n_selected_features]
            The input samples with only the selected features.
        """"""
    X = self._validate_data(X, dtype=None, accept_sparse='csr', force_all_finite=not _safe_tags(self, key='allow_nan'), reset=False)
    return self._transform(X)",[]
./sklearn/feature_selection/_base.py,_transform,reduce_to_selected_features,92,104,"def _transform(self, X):
    """"""Reduce X to the selected features.""""""
    mask = self.get_support()
    if not mask.any():
        warnings.warn('No features were selected: either the data is too noisy or the selection test too strict.', UserWarning)
        return np.empty(0, dtype=X.dtype).reshape((X.shape[0], 0))
    if len(mask) != X.shape[1]:
        raise ValueError('X has a different shape than during fitting.')
    return X[:, safe_mask(X, mask)]","def reduce_to_selected_features(self, X):
    """"""Reduce X to the selected features.""""""
    mask = self.get_support()
    if not mask.any():
        warnings.warn('No features were selected: either the data is too noisy or the selection test too strict.', UserWarning)
        return np.empty(0, dtype=X.dtype).reshape((X.shape[0], 0))
    if len(mask) != X.shape[1]:
        raise ValueError('X has a different shape than during fitting.')
    return X[:, safe_mask(X, mask)]","[{""var"": ""mask"", ""rename"": ""selected_features_mask""}]"
./sklearn/feature_selection/_base.py,inverse_transform,restore_original_feature_dimensions,106,144,"def inverse_transform(self, X):
    """"""Reverse the transformation operation.

        Parameters
        ----------
        X : array of shape [n_samples, n_selected_features]
            The input samples.

        Returns
        -------
        X_r : array of shape [n_samples, n_original_features]
            `X` with columns of zeros inserted where features would have
            been removed by :meth:`transform`.
        """"""
    if issparse(X):
        X = X.tocsc()
        it = self.inverse_transform(np.diff(X.indptr).reshape(1, -1))
        col_nonzeros = it.ravel()
        indptr = np.concatenate([[0], np.cumsum(col_nonzeros)])
        Xt = csc_matrix((X.data, X.indices, indptr), shape=(X.shape[0], len(indptr) - 1), dtype=X.dtype)
        return Xt
    support = self.get_support()
    X = check_array(X, dtype=None)
    if support.sum() != X.shape[1]:
        raise ValueError('X has a different shape than during fitting.')
    if X.ndim == 1:
        X = X[None, :]
    Xt = np.zeros((X.shape[0], support.size), dtype=X.dtype)
    Xt[:, support] = X
    return Xt","def restore_original_feature_dimensions(self, X):
    """"""Reverse the transformation operation.

        Parameters
        ----------
        X : array of shape [n_samples, n_selected_features]
            The input samples.

        Returns
        -------
        X_r : array of shape [n_samples, n_original_features]
            `X` with columns of zeros inserted where features would have
            been removed by :meth:`transform`.
        """"""
    if issparse(X):
        X = X.tocsc()
        it = self.inverse_transform(np.diff(X.indptr).reshape(1, -1))
        col_nonzeros = it.ravel()
        indptr = np.concatenate([[0], np.cumsum(col_nonzeros)])
        Xt = csc_matrix((X.data, X.indices, indptr), shape=(X.shape[0], len(indptr) - 1), dtype=X.dtype)
        return Xt
    support = self.get_support()
    X = check_array(X, dtype=None)
    if support.sum() != X.shape[1]:
        raise ValueError('X has a different shape than during fitting.')
    if X.ndim == 1:
        X = X[None, :]
    Xt = np.zeros((X.shape[0], support.size), dtype=X.dtype)
    Xt[:, support] = X
    return Xt","[{""var"": ""Xt"", ""rename"": ""restored_feature_matrix""}, {""var"": ""support"", ""rename"": ""feature_support_mask""}, {""var"": ""it"", ""rename"": ""inverse_transformed_counts""}, {""var"": ""indptr"", ""rename"": ""column_index_pointer""}, {""var"": ""col_nonzeros"", ""rename"": ""column_nonzero_counts""}]"
