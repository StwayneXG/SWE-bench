file,method_name,new_method_name,start_line,end_line,original_code,code,var
./xarray/core/dataarray.py,integrate,trapezoidal_integrate,3483,3532,"def integrate(self, dim: Union[Hashable, Sequence[Hashable]], datetime_unit: str=None) -> 'DataArray':
    """""" integrate the array with the trapezoidal rule.

        .. note::
            This feature is limited to simple cartesian geometry, i.e. dim
            must be one dimensional.

        Parameters
        ----------
        dim : hashable, or sequence of hashable
            Coordinate(s) used for the integration.
        datetime_unit : {""Y"", ""M"", ""W"", ""D"", ""h"", ""m"", ""s"", ""ms"", ""us"", ""ns"",                          ""ps"", ""fs"", ""as""}, optional
            Can be used to specify the unit if datetime coordinate is used.

        Returns
        -------
        integrated: DataArray

        See also
        --------
        numpy.trapz: corresponding numpy function

        Examples
        --------

        >>> da = xr.DataArray(
        ...     np.arange(12).reshape(4, 3),
        ...     dims=[""x"", ""y""],
        ...     coords={""x"": [0, 0.1, 1.1, 1.2]},
        ... )
        >>> da
        <xarray.DataArray (x: 4, y: 3)>
        array([[ 0,  1,  2],
               [ 3,  4,  5],
               [ 6,  7,  8],
               [ 9, 10, 11]])
        Coordinates:
          * x        (x) float64 0.0 0.1 1.1 1.2
        Dimensions without coordinates: y
        >>>
        >>> da.integrate(""x"")
        <xarray.DataArray (y: 3)>
        array([5.4, 6.6, 7.8])
        Dimensions without coordinates: y
        """"""
    ds = self._to_temp_dataset().integrate(dim, datetime_unit)
    return self._from_temp_dataset(ds)","def trapezoidal_integrate(self, dim: Union[Hashable, Sequence[Hashable]], datetime_unit: str=None) -> 'DataArray':
    """""" integrate the array with the trapezoidal rule.

        .. note::
            This feature is limited to simple cartesian geometry, i.e. dim
            must be one dimensional.

        Parameters
        ----------
        dim : hashable, or sequence of hashable
            Coordinate(s) used for the integration.
        datetime_unit : {""Y"", ""M"", ""W"", ""D"", ""h"", ""m"", ""s"", ""ms"", ""us"", ""ns"",                          ""ps"", ""fs"", ""as""}, optional
            Can be used to specify the unit if datetime coordinate is used.

        Returns
        -------
        integrated: DataArray

        See also
        --------
        numpy.trapz: corresponding numpy function

        Examples
        --------

        >>> da = xr.DataArray(
        ...     np.arange(12).reshape(4, 3),
        ...     dims=[""x"", ""y""],
        ...     coords={""x"": [0, 0.1, 1.1, 1.2]},
        ... )
        >>> da
        <xarray.DataArray (x: 4, y: 3)>
        array([[ 0,  1,  2],
               [ 3,  4,  5],
               [ 6,  7,  8],
               [ 9, 10, 11]])
        Coordinates:
          * x        (x) float64 0.0 0.1 1.1 1.2
        Dimensions without coordinates: y
        >>>
        >>> da.integrate(""x"")
        <xarray.DataArray (y: 3)>
        array([5.4, 6.6, 7.8])
        Dimensions without coordinates: y
        """"""
    ds = self._to_temp_dataset().integrate(dim, datetime_unit)
    return self._from_temp_dataset(ds)","[{""var"": ""ds"", ""rename"": ""integrated_dataset""}]"
./xarray/core/dataarray.py,unify_chunks,harmonize_chunk_sizes_across_dimensions,3534,3548,"def unify_chunks(self) -> 'DataArray':
    """"""Unify chunk size along all chunked dimensions of this DataArray.

        Returns
        -------

        DataArray with consistent chunk sizes for all dask-array variables

        See Also
        --------

        dask.array.core.unify_chunks
        """"""
    ds = self._to_temp_dataset().unify_chunks()
    return self._from_temp_dataset(ds)","def harmonize_chunk_sizes_across_dimensions(self) -> 'DataArray':
    """"""Unify chunk size along all chunked dimensions of this DataArray.

        Returns
        -------

        DataArray with consistent chunk sizes for all dask-array variables

        See Also
        --------

        dask.array.core.unify_chunks
        """"""
    ds = self._to_temp_dataset().unify_chunks()
    return self._from_temp_dataset(ds)","[{""var"": ""ds"", ""rename"": ""unified_chunked_dataset""}]"
./xarray/core/dataarray.py,map_blocks,apply_function_to_dataarray_blocks,3550,3653,"def map_blocks(self, func: 'Callable[..., T_DSorDA]', args: Sequence[Any]=(), kwargs: Mapping[str, Any]=None, template: Union['DataArray', 'Dataset']=None) -> 'T_DSorDA':
    """"""
        Apply a function to each block of this DataArray.

        .. warning::
            This method is experimental and its signature may change.

        Parameters
        ----------
        func : callable
            User-provided function that accepts a DataArray as its first
            parameter. The function will receive a subset or 'block' of this DataArray (see below),
            corresponding to one chunk along each chunked dimension. ``func`` will be
            executed as ``func(subset_dataarray, *subset_args, **kwargs)``.

            This function must return either a single DataArray or a single Dataset.

            This function cannot add a new chunked dimension.
        args : sequence
            Passed to func after unpacking and subsetting any xarray objects by blocks.
            xarray objects in args must be aligned with this object, otherwise an error is raised.
        kwargs : mapping
            Passed verbatim to func after unpacking. xarray objects, if any, will not be
            subset to blocks. Passing dask collections in kwargs is not allowed.
        template : DataArray or Dataset, optional
            xarray object representing the final result after compute is called. If not provided,
            the function will be first run on mocked-up data, that looks like this object but
            has sizes 0, to determine properties of the returned object such as dtype,
            variable names, attributes, new dimensions and new indexes (if any).
            ``template`` must be provided if the function changes the size of existing dimensions.
            When provided, ``attrs`` on variables in `template` are copied over to the result. Any
            ``attrs`` set by ``func`` will be ignored.

        Returns
        -------
        A single DataArray or Dataset with dask backend, reassembled from the outputs of the
        function.

        Notes
        -----
        This function is designed for when ``func`` needs to manipulate a whole xarray object
        subset to each block. In the more common case where ``func`` can work on numpy arrays, it is
        recommended to use ``apply_ufunc``.

        If none of the variables in this object is backed by dask arrays, calling this function is
        equivalent to calling ``func(obj, *args, **kwargs)``.

        See Also
        --------
        dask.array.map_blocks, xarray.apply_ufunc, xarray.Dataset.map_blocks,
        xarray.DataArray.map_blocks

        Examples
        --------

        Calculate an anomaly from climatology using ``.groupby()``. Using
        ``xr.map_blocks()`` allows for parallel operations with knowledge of ``xarray``,
        its indices, and its methods like ``.groupby()``.

        >>> def calculate_anomaly(da, groupby_type=""time.month""):
        ...     gb = da.groupby(groupby_type)
        ...     clim = gb.mean(dim=""time"")
        ...     return gb - clim
        ...
        >>> time = xr.cftime_range(""1990-01"", ""1992-01"", freq=""M"")
        >>> month = xr.DataArray(time.month, coords={""time"": time}, dims=[""time""])
        >>> np.random.seed(123)
        >>> array = xr.DataArray(
        ...     np.random.rand(len(time)),
        ...     dims=[""time""],
        ...     coords={""time"": time, ""month"": month},
        ... ).chunk()
        >>> array.map_blocks(calculate_anomaly, template=array).compute()
        <xarray.DataArray (time: 24)>
        array([ 0.12894847,  0.11323072, -0.0855964 , -0.09334032,  0.26848862,
                0.12382735,  0.22460641,  0.07650108, -0.07673453, -0.22865714,
               -0.19063865,  0.0590131 , -0.12894847, -0.11323072,  0.0855964 ,
                0.09334032, -0.26848862, -0.12382735, -0.22460641, -0.07650108,
                0.07673453,  0.22865714,  0.19063865, -0.0590131 ])
        Coordinates:
          * time     (time) object 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 1 2 3 4 5 6 7 8 9 10 11 12 1 2 3 4 5 6 7 8 9 10 11 12

        Note that one must explicitly use ``args=[]`` and ``kwargs={}`` to pass arguments
        to the function being applied in ``xr.map_blocks()``:

        >>> array.map_blocks(
        ...     calculate_anomaly, kwargs={""groupby_type"": ""time.year""}, template=array
        ... )  # doctest: +ELLIPSIS
        <xarray.DataArray (time: 24)>
        dask.array<calculate_anomaly-...-<this, shape=(24,), dtype=float64, chunksize=(24,), chunktype=numpy.ndarray>
        Coordinates:
          * time     (time) object 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 dask.array<chunksize=(24,), meta=np.ndarray>
        """"""
    from .parallel import map_blocks
    return map_blocks(func, self, args, kwargs, template)","def apply_function_to_dataarray_blocks(self, func: 'Callable[..., T_DSorDA]', args: Sequence[Any]=(), kwargs: Mapping[str, Any]=None, template: Union['DataArray', 'Dataset']=None) -> 'T_DSorDA':
    """"""
        Apply a function to each block of this DataArray.

        .. warning::
            This method is experimental and its signature may change.

        Parameters
        ----------
        func : callable
            User-provided function that accepts a DataArray as its first
            parameter. The function will receive a subset or 'block' of this DataArray (see below),
            corresponding to one chunk along each chunked dimension. ``func`` will be
            executed as ``func(subset_dataarray, *subset_args, **kwargs)``.

            This function must return either a single DataArray or a single Dataset.

            This function cannot add a new chunked dimension.
        args : sequence
            Passed to func after unpacking and subsetting any xarray objects by blocks.
            xarray objects in args must be aligned with this object, otherwise an error is raised.
        kwargs : mapping
            Passed verbatim to func after unpacking. xarray objects, if any, will not be
            subset to blocks. Passing dask collections in kwargs is not allowed.
        template : DataArray or Dataset, optional
            xarray object representing the final result after compute is called. If not provided,
            the function will be first run on mocked-up data, that looks like this object but
            has sizes 0, to determine properties of the returned object such as dtype,
            variable names, attributes, new dimensions and new indexes (if any).
            ``template`` must be provided if the function changes the size of existing dimensions.
            When provided, ``attrs`` on variables in `template` are copied over to the result. Any
            ``attrs`` set by ``func`` will be ignored.

        Returns
        -------
        A single DataArray or Dataset with dask backend, reassembled from the outputs of the
        function.

        Notes
        -----
        This function is designed for when ``func`` needs to manipulate a whole xarray object
        subset to each block. In the more common case where ``func`` can work on numpy arrays, it is
        recommended to use ``apply_ufunc``.

        If none of the variables in this object is backed by dask arrays, calling this function is
        equivalent to calling ``func(obj, *args, **kwargs)``.

        See Also
        --------
        dask.array.map_blocks, xarray.apply_ufunc, xarray.Dataset.map_blocks,
        xarray.DataArray.map_blocks

        Examples
        --------

        Calculate an anomaly from climatology using ``.groupby()``. Using
        ``xr.map_blocks()`` allows for parallel operations with knowledge of ``xarray``,
        its indices, and its methods like ``.groupby()``.

        >>> def calculate_anomaly(da, groupby_type=""time.month""):
        ...     gb = da.groupby(groupby_type)
        ...     clim = gb.mean(dim=""time"")
        ...     return gb - clim
        ...
        >>> time = xr.cftime_range(""1990-01"", ""1992-01"", freq=""M"")
        >>> month = xr.DataArray(time.month, coords={""time"": time}, dims=[""time""])
        >>> np.random.seed(123)
        >>> array = xr.DataArray(
        ...     np.random.rand(len(time)),
        ...     dims=[""time""],
        ...     coords={""time"": time, ""month"": month},
        ... ).chunk()
        >>> array.map_blocks(calculate_anomaly, template=array).compute()
        <xarray.DataArray (time: 24)>
        array([ 0.12894847,  0.11323072, -0.0855964 , -0.09334032,  0.26848862,
                0.12382735,  0.22460641,  0.07650108, -0.07673453, -0.22865714,
               -0.19063865,  0.0590131 , -0.12894847, -0.11323072,  0.0855964 ,
                0.09334032, -0.26848862, -0.12382735, -0.22460641, -0.07650108,
                0.07673453,  0.22865714,  0.19063865, -0.0590131 ])
        Coordinates:
          * time     (time) object 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 1 2 3 4 5 6 7 8 9 10 11 12 1 2 3 4 5 6 7 8 9 10 11 12

        Note that one must explicitly use ``args=[]`` and ``kwargs={}`` to pass arguments
        to the function being applied in ``xr.map_blocks()``:

        >>> array.map_blocks(
        ...     calculate_anomaly, kwargs={""groupby_type"": ""time.year""}, template=array
        ... )  # doctest: +ELLIPSIS
        <xarray.DataArray (time: 24)>
        dask.array<calculate_anomaly-...-<this, shape=(24,), dtype=float64, chunksize=(24,), chunktype=numpy.ndarray>
        Coordinates:
          * time     (time) object 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 dask.array<chunksize=(24,), meta=np.ndarray>
        """"""
    from .parallel import map_blocks
    return map_blocks(func, self, args, kwargs, template)",[]
./xarray/core/dataset.py,integrate,trapezoidal_integration_cartesian,5966,6023,"def integrate(self, coord, datetime_unit=None):
    """""" integrate the array with the trapezoidal rule.

        .. note::
            This feature is limited to simple cartesian geometry, i.e. coord
            must be one dimensional.

        Parameters
        ----------
        coord: str, or sequence of str
            Coordinate(s) used for the integration.
        datetime_unit : {""Y"", ""M"", ""W"", ""D"", ""h"", ""m"", ""s"", ""ms"", ""us"", ""ns"",                          ""ps"", ""fs"", ""as""}, optional
            Can be specify the unit if datetime coordinate is used.

        Returns
        -------
        integrated : Dataset

        See also
        --------
        DataArray.integrate
        numpy.trapz: corresponding numpy function

        Examples
        --------
        >>> ds = xr.Dataset(
        ...     data_vars={""a"": (""x"", [5, 5, 6, 6]), ""b"": (""x"", [1, 2, 1, 0])},
        ...     coords={""x"": [0, 1, 2, 3], ""y"": (""x"", [1, 7, 3, 5])},
        ... )
        >>> ds
        <xarray.Dataset>
        Dimensions:  (x: 4)
        Coordinates:
          * x        (x) int64 0 1 2 3
            y        (x) int64 1 7 3 5
        Data variables:
            a        (x) int64 5 5 6 6
            b        (x) int64 1 2 1 0
        >>> ds.integrate(""x"")
        <xarray.Dataset>
        Dimensions:  ()
        Data variables:
            a        float64 16.5
            b        float64 3.5
        >>> ds.integrate(""y"")
        <xarray.Dataset>
        Dimensions:  ()
        Data variables:
            a        float64 20.0
            b        float64 4.0
        """"""
    if not isinstance(coord, (list, tuple)):
        coord = (coord,)
    result = self
    for c in coord:
        result = result._integrate_one(c, datetime_unit=datetime_unit)
    return result","def trapezoidal_integration_cartesian(self, coord, datetime_unit=None):
    """""" integrate the array with the trapezoidal rule.

        .. note::
            This feature is limited to simple cartesian geometry, i.e. coord
            must be one dimensional.

        Parameters
        ----------
        coord: str, or sequence of str
            Coordinate(s) used for the integration.
        datetime_unit : {""Y"", ""M"", ""W"", ""D"", ""h"", ""m"", ""s"", ""ms"", ""us"", ""ns"",                          ""ps"", ""fs"", ""as""}, optional
            Can be specify the unit if datetime coordinate is used.

        Returns
        -------
        integrated : Dataset

        See also
        --------
        DataArray.integrate
        numpy.trapz: corresponding numpy function

        Examples
        --------
        >>> ds = xr.Dataset(
        ...     data_vars={""a"": (""x"", [5, 5, 6, 6]), ""b"": (""x"", [1, 2, 1, 0])},
        ...     coords={""x"": [0, 1, 2, 3], ""y"": (""x"", [1, 7, 3, 5])},
        ... )
        >>> ds
        <xarray.Dataset>
        Dimensions:  (x: 4)
        Coordinates:
          * x        (x) int64 0 1 2 3
            y        (x) int64 1 7 3 5
        Data variables:
            a        (x) int64 5 5 6 6
            b        (x) int64 1 2 1 0
        >>> ds.integrate(""x"")
        <xarray.Dataset>
        Dimensions:  ()
        Data variables:
            a        float64 16.5
            b        float64 3.5
        >>> ds.integrate(""y"")
        <xarray.Dataset>
        Dimensions:  ()
        Data variables:
            a        float64 20.0
            b        float64 4.0
        """"""
    if not isinstance(coord, (list, tuple)):
        coord = (coord,)
    result = self
    for c in coord:
        result = result._integrate_one(c, datetime_unit=datetime_unit)
    return result","[{""var"": ""c"", ""rename"": ""coordinate""}, {""var"": ""result"", ""rename"": ""cumulative_integration_result""}]"
